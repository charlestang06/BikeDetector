{"cells":[{"cell_type":"markdown","metadata":{"id":"license"},"source":["##### *Copyright 2021 Google LLC*\n","*Licensed under the Apache License, Version 2.0 (the \"License\")*"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"both","id":"rKwqeqWBXANA"},"outputs":[],"source":["# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."]},{"cell_type":"code","source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)\n","\n","from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UPpTl1FQiogN","executionInfo":{"status":"ok","timestamp":1668870181889,"user_tz":300,"elapsed":225,"user":{"displayName":"Charles Tang","userId":"08254346733793913295"}},"outputId":"c77e90ba-f104-4f96-abb2-d0a77e96bbe6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sat Nov 19 15:03:01 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   29C    P0    44W / 400W |      0MiB / 40536MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Your runtime has 89.6 gigabytes of available RAM\n","\n","You are using a high-RAM runtime!\n"]}]},{"cell_type":"markdown","metadata":{"id":"Gb7qyhNL1yWt"},"source":["# Retrain EfficientDet for the Edge TPU with TensorFlow Lite Model Maker"]},{"cell_type":"markdown","source":[],"metadata":{"id":"oYMA2djOXxiV"}},{"cell_type":"code","source":["# jupyter notebook --NotebookApp.allow_origin='https://colab.research.google.com' --port=8888 --NotebookApp.port_retries=0"],"metadata":{"id":"MoKI0j8hXwrf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"u2eVTwlmIOIk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668870196063,"user_tz":300,"elapsed":13339,"user":{"displayName":"Charles Tang","userId":"08254346733793913295"}},"outputId":"674e478f-4c96-4cb3-9ac7-5424e85241bf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"2vvAObmTqglq"},"source":["## Import the required packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qhl8lqVamEty","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668870275648,"user_tz":300,"elapsed":79596,"user":{"displayName":"Charles Tang","userId":"08254346733793913295"}},"outputId":"b86a8fc9-f0cf-4e84-bb3d-239fd1a53867"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 577 kB 4.9 MB/s \n","\u001b[K     |████████████████████████████████| 60.9 MB 1.4 MB/s \n","\u001b[K     |████████████████████████████████| 128 kB 83.5 MB/s \n","\u001b[K     |████████████████████████████████| 840 kB 77.2 MB/s \n","\u001b[K     |████████████████████████████████| 3.4 MB 73.6 MB/s \n","\u001b[K     |████████████████████████████████| 1.1 MB 77.6 MB/s \n","\u001b[K     |████████████████████████████████| 10.9 MB 80.1 MB/s \n","\u001b[K     |████████████████████████████████| 1.3 MB 81.8 MB/s \n","\u001b[K     |████████████████████████████████| 87 kB 8.1 MB/s \n","\u001b[K     |████████████████████████████████| 238 kB 78.6 MB/s \n","\u001b[K     |████████████████████████████████| 77 kB 7.0 MB/s \n","\u001b[K     |████████████████████████████████| 25.3 MB 85.2 MB/s \n","\u001b[K     |████████████████████████████████| 497.9 MB 2.9 kB/s \n","\u001b[K     |████████████████████████████████| 352 kB 77.1 MB/s \n","\u001b[K     |████████████████████████████████| 462 kB 78.7 MB/s \n","\u001b[K     |████████████████████████████████| 5.8 MB 68.6 MB/s \n","\u001b[K     |████████████████████████████████| 1.4 MB 62.0 MB/s \n","\u001b[K     |████████████████████████████████| 40 kB 6.6 MB/s \n","\u001b[K     |████████████████████████████████| 216 kB 83.8 MB/s \n","\u001b[?25h  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install -q tflite-model-maker"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XtxiUeZEiXpt"},"outputs":[],"source":["import numpy as np\n","import os\n","\n","from tflite_model_maker.config import ExportFormat\n","from tflite_model_maker import model_spec\n","from tflite_model_maker import object_detector\n","\n","import tensorflow as tf\n","assert tf.__version__.startswith('2')\n","\n","tf.get_logger().setLevel('ERROR')\n","from absl import logging\n","logging.set_verbosity(logging.ERROR)"]},{"cell_type":"markdown","metadata":{"id":"H0XM-oIfhgQ7"},"source":["## Load the training data\n"]},{"cell_type":"markdown","metadata":{"id":"ZljJ25RAnj5x"},"source":["### (Optional) Load your own Pascal VOC dataset"]},{"cell_type":"markdown","metadata":{"id":"Ei5BahmPn_wR"},"source":["To use your custom dataset, you need to modify a few variables here, such as your ZIP filename, your label map, and the path to your images/annotations:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mz_suhWiqc7A"},"outputs":[],"source":["# Your labels map as a dictionary (zero is reserved):\n","label_map = {1: 'Cyclist'} "]},{"cell_type":"markdown","metadata":{"id":"d8Rh3IWRb0xw"},"source":["Now you're ready to train the model with your custom dataset. But before you run the notebook, you should also skip to the [Export to TensorFlow Lite](#scrollTo=_yB_XMpqGlLs) section and change the `TFLITE_FILENAME` and `LABLES_FILENAME` for your exported files.\n","\n","Then run the whole notebook by clicking **Runtime > Run all**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KWROlVNA54xZ"},"outputs":[],"source":["# We need to instantiate a separate DataLoader for each split dataset\n","os.chdir('/content/drive/My Drive/STEM_1/dataset')\n","train_data = object_detector.DataLoader(tfrecord_file_patten='/content/drive/My Drive/STEM_1/dataset/onlybike/train1.record', size=12000, label_map=label_map)\n","validation_data = object_detector.DataLoader(\n","      '/content/drive/My Drive/STEM_1/dataset/onlybike/test1.record', size=1000, label_map=label_map)"]},{"cell_type":"markdown","metadata":{"id":"S8clx0KPutCM"},"source":["## Select the model spec"]},{"cell_type":"markdown","metadata":{"id":"vn61LJ9QbOPi"},"source":["Model Maker supports the EfficientDet-Lite family of object detection models that are compatible with the Edge TPU. (EfficientDet-Lite is derived from [EfficientDet](https://ai.googleblog.com/2020/04/efficientdet-towards-scalable-and.html), which offers state-of-the-art accuracy in a small model size). There are several model sizes you can choose from:\n","\n","|| Model architecture | Size(MB)* | Latency(ms)** | Average Precision*** |\n","|-|--------------------|-----------|---------------|----------------------|\n","|| EfficientDet-Lite0 | 5.7       | 37.4            | 30.4%               |\n","|| EfficientDet-Lite1 | 7.6       | 56.3            | 34.3%               |\n","|| EfficientDet-Lite2 | 10.2      | 104.6           | 36.0%               |\n","|| EfficientDet-Lite3 | 14.4      | 107.6           | 39.4%               |\n","| <td colspan=4><br><i>* File size of the compiled Edge TPU models. <br/>** Latency measured on a desktop CPU with a Coral USB Accelerator. <br/>*** Average Precision is the mAP (mean Average Precision) on the COCO 2017 validation dataset.</i></td> |\n","\n","Beware that the Lite2 and Lite3 models do not fit onto the Edge TPU's onboard memory, so you'll see even greater latency when using those, due to the cost of fetching data from the host system memory. Maybe this extra latency is okay for your application, but if it's not and you require the precision of the larger models, then you can [pipeline the model across multiple Edge TPUs](https://coral.ai/docs/edgetpu/pipeline/) (more about this when we compile the model below)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SM9gePHw9Jv1"},"outputs":[],"source":["spec = object_detector.EfficientDetLite1Spec(model_dir='/content/drive/My Drive/STEM_1/dataset/try5/all_layers')"]},{"cell_type":"markdown","metadata":{"id":"rnCzdzs0-Rbo"},"source":["The [`EfficientDetLite0Spec`](https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker/object_detector/EfficientDetLite0Spec) constructor also supports several arguments that specify training options, such as the max number of detections (default is 25 for the TF Lite model) and whether to use Cloud TPUs for training. You can also use the constructor to specify the number of training epochs and the batch size, but you can also specify those in the next step."]},{"cell_type":"code","source":["# spec.config.var_freeze_expr = '(efficientnet|fpn_cells|resample_p6)'"],"metadata":{"id":"N4dujr--g8ap"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5qjq2UEHCLUi"},"source":["## Create and train the model"]},{"cell_type":"markdown","metadata":{"id":"2uZkLR6N6gDR"},"source":["Now we need to create our model according to the model spec, load our dataset into the model, specify training parameters, and begin training. \n","\n","Using Model Maker, we accomplished all of that with [`create()`](https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker/object_detector/create):"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kwlYdTcg63xy","colab":{"base_uri":"https://localhost:8080/"},"outputId":"522e51b1-512b-4871-9449-2dfa15014d2e","executionInfo":{"status":"ok","timestamp":1668878678014,"user_tz":300,"elapsed":8376677,"user":{"displayName":"Charles Tang","userId":"08254346733793913295"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","1500/1500 [==============================] - 469s 280ms/step - det_loss: 0.3094 - cls_loss: 0.1879 - box_loss: 0.0024 - reg_l2_loss: 0.0709 - loss: 0.3802 - learning_rate: 0.0090 - gradient_norm: 2.2093\n","Epoch 2/20\n","1500/1500 [==============================] - 419s 279ms/step - det_loss: 0.2201 - cls_loss: 0.1451 - box_loss: 0.0015 - reg_l2_loss: 0.0713 - loss: 0.2913 - learning_rate: 0.0098 - gradient_norm: 1.8296\n","Epoch 3/20\n","1500/1500 [==============================] - 420s 280ms/step - det_loss: 0.2107 - cls_loss: 0.1394 - box_loss: 0.0014 - reg_l2_loss: 0.0714 - loss: 0.2821 - learning_rate: 0.0096 - gradient_norm: 1.7076\n","Epoch 4/20\n","1500/1500 [==============================] - 419s 279ms/step - det_loss: 0.1901 - cls_loss: 0.1288 - box_loss: 0.0012 - reg_l2_loss: 0.0714 - loss: 0.2615 - learning_rate: 0.0092 - gradient_norm: 1.5906\n","Epoch 5/20\n","1500/1500 [==============================] - 416s 277ms/step - det_loss: 0.1837 - cls_loss: 0.1249 - box_loss: 0.0012 - reg_l2_loss: 0.0713 - loss: 0.2550 - learning_rate: 0.0087 - gradient_norm: 1.5127\n","Epoch 6/20\n","1500/1500 [==============================] - 415s 277ms/step - det_loss: 0.1817 - cls_loss: 0.1227 - box_loss: 0.0012 - reg_l2_loss: 0.0711 - loss: 0.2528 - learning_rate: 0.0081 - gradient_norm: 1.4897\n","Epoch 7/20\n","1500/1500 [==============================] - 414s 276ms/step - det_loss: 0.1689 - cls_loss: 0.1163 - box_loss: 0.0011 - reg_l2_loss: 0.0709 - loss: 0.2398 - learning_rate: 0.0074 - gradient_norm: 1.4592\n","Epoch 8/20\n","1500/1500 [==============================] - 412s 275ms/step - det_loss: 0.1663 - cls_loss: 0.1146 - box_loss: 0.0010 - reg_l2_loss: 0.0706 - loss: 0.2369 - learning_rate: 0.0066 - gradient_norm: 1.4294\n","Epoch 9/20\n","1500/1500 [==============================] - 415s 277ms/step - det_loss: 0.1650 - cls_loss: 0.1135 - box_loss: 0.0010 - reg_l2_loss: 0.0704 - loss: 0.2354 - learning_rate: 0.0058 - gradient_norm: 1.4586\n","Epoch 10/20\n","1500/1500 [==============================] - 415s 276ms/step - det_loss: 0.1544 - cls_loss: 0.1084 - box_loss: 9.1917e-04 - reg_l2_loss: 0.0702 - loss: 0.2246 - learning_rate: 0.0050 - gradient_norm: 1.3890\n","Epoch 11/20\n","1500/1500 [==============================] - 416s 277ms/step - det_loss: 0.1558 - cls_loss: 0.1080 - box_loss: 9.5674e-04 - reg_l2_loss: 0.0699 - loss: 0.2257 - learning_rate: 0.0042 - gradient_norm: 1.4202\n","Epoch 12/20\n","1500/1500 [==============================] - 414s 276ms/step - det_loss: 0.1464 - cls_loss: 0.1026 - box_loss: 8.7542e-04 - reg_l2_loss: 0.0697 - loss: 0.2161 - learning_rate: 0.0034 - gradient_norm: 1.3792\n","Epoch 13/20\n","1500/1500 [==============================] - 414s 276ms/step - det_loss: 0.1436 - cls_loss: 0.1018 - box_loss: 8.3537e-04 - reg_l2_loss: 0.0695 - loss: 0.2131 - learning_rate: 0.0026 - gradient_norm: 1.3784\n","Epoch 14/20\n","1500/1500 [==============================] - 415s 277ms/step - det_loss: 0.1480 - cls_loss: 0.1032 - box_loss: 8.9760e-04 - reg_l2_loss: 0.0694 - loss: 0.2174 - learning_rate: 0.0019 - gradient_norm: 1.4091\n","Epoch 15/20\n","1500/1500 [==============================] - 414s 276ms/step - det_loss: 0.1342 - cls_loss: 0.0954 - box_loss: 7.7691e-04 - reg_l2_loss: 0.0693 - loss: 0.2035 - learning_rate: 0.0013 - gradient_norm: 1.3524\n","Epoch 16/20\n","1500/1500 [==============================] - 413s 275ms/step - det_loss: 0.1364 - cls_loss: 0.0969 - box_loss: 7.8967e-04 - reg_l2_loss: 0.0692 - loss: 0.2056 - learning_rate: 8.1894e-04 - gradient_norm: 1.3766\n","Epoch 17/20\n","1500/1500 [==============================] - 417s 278ms/step - det_loss: 0.1434 - cls_loss: 0.1003 - box_loss: 8.6296e-04 - reg_l2_loss: 0.0692 - loss: 0.2126 - learning_rate: 4.2635e-04 - gradient_norm: 1.4071\n","Epoch 18/20\n","1500/1500 [==============================] - 414s 276ms/step - det_loss: 0.1317 - cls_loss: 0.0937 - box_loss: 7.6095e-04 - reg_l2_loss: 0.0691 - loss: 0.2008 - learning_rate: 1.5853e-04 - gradient_norm: 1.3744\n","Epoch 19/20\n","1500/1500 [==============================] - 413s 275ms/step - det_loss: 0.1417 - cls_loss: 0.0995 - box_loss: 8.4452e-04 - reg_l2_loss: 0.0691 - loss: 0.2109 - learning_rate: 2.2759e-05 - gradient_norm: 1.4572\n","Epoch 20/20\n","1500/1500 [==============================] - 416s 277ms/step - det_loss: 0.1458 - cls_loss: 0.1015 - box_loss: 8.8639e-04 - reg_l2_loss: 0.0691 - loss: 0.2149 - learning_rate: 2.2759e-05 - gradient_norm: 1.4521\n"]}],"source":["model = object_detector.create(train_data=train_data, \n","                               model_spec=spec, \n","                               epochs=20, \n","                               batch_size=8, \n","                               train_whole_model=True)"]},{"cell_type":"markdown","metadata":{"id":"3n5-o3vvGfnJ"},"source":["## Evaluate the model"]},{"cell_type":"markdown","metadata":{"id":"-BzCHLWJ6h7q"},"source":["Now we'll use the test dataset to evaluate how well the model performs with data it has never seen before.\n","\n","The [`evaluate()`](https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker/object_detector/ObjectDetector#evaluate) method provides output in the style of [COCO evaluation metrics](https://cocodataset.org/#detection-eval):"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8xmnl6Yy7ARn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668878985628,"user_tz":300,"elapsed":30314,"user":{"displayName":"Charles Tang","userId":"08254346733793913295"}},"outputId":"748bebe7-3343-4c88-c5f5-de1f4ca7a78c"},"outputs":[{"output_type":"stream","name":"stdout","text":["12/16 [=====================>........] - ETA: 2s\n"]},{"output_type":"execute_result","data":{"text/plain":["{'AP': 0.82103777,\n"," 'AP50': 0.9777668,\n"," 'AP75': 0.9295557,\n"," 'APs': 0.012121212,\n"," 'APm': 0.50447285,\n"," 'APl': 0.84338975,\n"," 'ARmax1': 0.4859522,\n"," 'ARmax10': 0.85792905,\n"," 'ARmax100': 0.8705286,\n"," 'ARs': 0.4,\n"," 'ARm': 0.6587156,\n"," 'ARl': 0.8890637,\n"," 'AP_/Cyclist': 0.82103777}"]},"metadata":{},"execution_count":14}],"source":["model.evaluate(validation_data)"]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3A4Sd8ICZ1NY","executionInfo":{"status":"ok","timestamp":1668878985630,"user_tz":300,"elapsed":31,"user":{"displayName":"Charles Tang","userId":"08254346733793913295"}},"outputId":"08444452-41ea-4a04-9854-ad61632e0fe6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," keras_layer (KerasLayer)    multiple                  4234512   \n","                                                                 \n"," class_net/class-predict (Se  multiple                 2394      \n"," parableConv2D)                                                  \n","                                                                 \n"," box_net/box-predict (Separa  multiple                 3996      \n"," bleConv2D)                                                      \n","                                                                 \n","=================================================================\n","Total params: 4,240,902\n","Trainable params: 4,177,830\n","Non-trainable params: 63,072\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"PEon9xd2BDS_"},"source":["Because the default batch size for [EfficientDetLite models](https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker/object_detector/EfficientDetSpec) is 64, this needs only 1 step to go through all 25 images in the salad test set. You can also specify the `batch_size` argument when you call [`evaluate()`](https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker/object_detector/ObjectDetector#evaluate)."]},{"cell_type":"markdown","metadata":{"id":"_yB_XMpqGlLs"},"source":["## Export to TensorFlow Lite"]},{"cell_type":"markdown","metadata":{"id":"CgCDMe0e6jlT"},"source":["Next, we'll export the model to the TensorFlow Lite format. By default, the [`export()`](https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker/object_detector/ObjectDetector#export) method performs [full integer post-training quantization](https://www.tensorflow.org/lite/performance/post_training_quantization#full_integer_quantization), which is exactly what we need for compatibility with the Edge TPU. (Model Maker uses the same dataset we gave to our model spec as a representative dataset, which is required for full-int quantization.)\n","\n","We just need to specify the export directory and format. By default, it exports to TF Lite, but we also want a labels file, so we declare both:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Cu9cxX5Qu-e"},"outputs":[],"source":["TFLITE_FILENAME = 'efficientdet-lite-bikes.tflite'\n","LABELS_FILENAME = 'bikes-labels.txt'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rKd6qk7TbxYO"},"outputs":[],"source":["model.export(export_dir='/content/drive/My Drive/STEM_1/dataset/try5', tflite_filename=TFLITE_FILENAME, label_filename=LABELS_FILENAME,\n","             export_format=[ExportFormat.TFLITE, ExportFormat.LABEL])"]},{"cell_type":"markdown","metadata":{"id":"b94hZ-exOCRB"},"source":["### Evaluate the TF Lite model"]},{"cell_type":"markdown","metadata":{"id":"ZQpahAIBqBPp"},"source":["Exporting the model to TensorFlow Lite can affect the model accuracy, due to the reduced numerical precision from quantization and because the original TensorFlow model uses per-class [non-max supression (NMS)](https://www.coursera.org/lecture/convolutional-neural-networks/non-max-suppression-dvrjH) for post-processing, while the TF Lite model uses global NMS, which is faster but less accurate.\n","\n","Therefore you should always evaluate the exported TF Lite model and be sure it still meets your requirements:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RS3Ell_lqH4e","colab":{"base_uri":"https://localhost:8080/","height":328},"executionInfo":{"status":"error","timestamp":1668869985530,"user_tz":300,"elapsed":49987,"user":{"displayName":"Charles Tang","userId":"08254346733793913295"}},"outputId":"25a6ad9a-b92f-4643-e02c-1d0e46088c1e"},"outputs":[{"output_type":"stream","name":"stdout","text":["   4/1000 [..............................] - ETA: 2:40:15"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-0b2c41feefbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_tflite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/STEM_1/dataset/try4/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mTFLITE_FILENAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_examples/lite/model_maker/core/task/object_detector.py\u001b[0m in \u001b[0;36mevaluate_tflite\u001b[0;34m(self, tflite_filepath, data)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     return self.model_spec.evaluate_tflite(tflite_filepath, ds, len(data),\n\u001b[0;32m--> 156\u001b[0;31m                                            data.annotations_json_file)\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_export_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaved_model_dir\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_examples/lite/model_maker/core/task/model_spec/object_detector_spec.py\u001b[0m in \u001b[0;36mevaluate_tflite\u001b[0;34m(self, tflite_filepath, dataset, steps, json_file)\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;31m# Get the output result after post-processing NMS op.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnms_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnms_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnms_boxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlite_runner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;31m# CLASS_OFFSET is used since label_id for `background` is 0 in label_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_examples/lite/model_maker/third_party/efficientdet/keras/eval_tflite.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m     91\u001b[0m       \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_detail\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dtype'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/interpreter.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m                                           self._subgraph_index)\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpreter_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_subgraph_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0moutput_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["model.evaluate_tflite(\"/content/drive/My Drive/STEM_1/dataset/try4/\"+TFLITE_FILENAME, validation_data)"]},{"cell_type":"markdown","metadata":{"id":"Ph88z7PdOeX7"},"source":["### Try the TFLite model"]},{"cell_type":"markdown","metadata":{"id":"me6_RwPZqNhX"},"source":["Just to be sure of things, let's run the model ourselves with an image from the test set. "]},{"cell_type":"markdown","metadata":{"id":"ZBecI78ZaxsO"},"source":["To simplify our code, we'll use the [PyCoral API](https://coral.ai/docs/reference/py/):"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TmgtGBqua1N3"},"outputs":[],"source":["! python3 -m pip install --extra-index-url https://google-coral.github.io/py-repo/ pycoral"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GkXtipXKqXp4"},"outputs":[],"source":["from PIL import Image\n","from PIL import ImageDraw\n","from PIL import ImageFont\n","\n","import tflite_runtime.interpreter as tflite \n","from pycoral.adapters import common\n","from pycoral.adapters import detect\n","from pycoral.utils.dataset import read_label_file\n","\n","def draw_objects(draw, objs, scale_factor, labels):\n","  \"\"\"Draws the bounding box and label for each object.\"\"\"\n","  COLORS = np.random.randint(0, 255, size=(len(labels), 3), dtype=np.uint8)\n","  for obj in objs:\n","    bbox = obj.bbox\n","    color = tuple(int(c) for c in COLORS[obj.id])\n","    draw.rectangle([(bbox.xmin * scale_factor, bbox.ymin * scale_factor),\n","                    (bbox.xmax * scale_factor, bbox.ymax * scale_factor)],\n","                   outline=color, width=3)\n","    font = ImageFont.truetype(\"LiberationSans-Regular.ttf\", size=15)\n","    draw.text((bbox.xmin * scale_factor + 4, bbox.ymin * scale_factor + 4),\n","              '%s\\n%.2f' % (labels.get(obj.id, obj.id), obj.score),\n","              fill=color, font=font)\n","\n","# Load the TF Lite model\n","labels = read_label_file('/content/drive/My Drive/STEM_1/dataset/export/' + LABELS_FILENAME)\n","interpreter = tflite.Interpreter('/content/drive/My Drive/STEM_1/dataset/export/' + TFLITE_FILENAME)\n","interpreter.allocate_tensors()\n","\n","# Resize the image for input\n","image = Image.open('/content/drive/My Drive/bike2.jpg')\n","_, scale = common.set_resized_input(\n","    interpreter, image.size, lambda size: image.resize(size, Image.ANTIALIAS))\n","\n","# Run inference\n","interpreter.invoke()\n","objs = detect.get_objects(interpreter, score_threshold=0.2, image_scale=scale)\n","\n","# Resize again to a reasonable size for display\n","display_width = 500\n","scale_factor = display_width / image.width\n","height_ratio = image.height / image.width\n","image = image.resize((display_width, int(display_width * height_ratio)))\n","draw_objects(ImageDraw.Draw(image), objs, scale_factor, labels)\n","image"]},{"cell_type":"markdown","metadata":{"id":"oxgWQyYOqZha"},"source":["## Compile for the Edge TPU\n"]},{"cell_type":"markdown","metadata":{"id":"A0QLiwCj9Pw6"},"source":["First we need to download the Edge TPU Compiler:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Oy3QIn_YqaRP"},"outputs":[],"source":["! curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n","\n","! echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n","\n","! sudo apt-get update\n","\n","! sudo apt-get install edgetpu-compiler"]},{"cell_type":"markdown","metadata":{"id":"qRWewhqFqeL_"},"source":["Before compiling the `.tflite` file for the Edge TPU, it's important to consider whether your model will fit into the Edge TPU memory. \n","\n","The Edge TPU has approximately 8 MB of SRAM for [caching model paramaters](https://coral.ai/docs/edgetpu/compiler/#parameter-data-caching), so any model close to or over 8 MB will not fit onto the Edge TPU memory. That means the inference times are longer, because some model parameters must be fetched from the host system memory.\n","\n","One way to elimiate the extra latency is to use [model pipelining](https://coral.ai/docs/edgetpu/pipeline/), which splits the model into segments that can run on separate Edge TPUs in series. This can significantly reduce the latency for big models.\n","\n","The following table provides recommendations for the number of Edge TPUs to use with each EfficientDet-Lite model.\n","\n","| Model architecture | Minimum TPUs | Recommended TPUs\n","|--------------------|-------|-------|\n","| EfficientDet-Lite0 | 1     | 1     |\n","| EfficientDet-Lite1 | 1     | 1     |\n","| EfficientDet-Lite2 | 1     | 2     |\n","| EfficientDet-Lite3 | 2     | 2     |\n","| EfficientDet-Lite4 | 2     | 3     |\n","\n","If you need extra Edge TPUs for your model, then update `NUMBER_OF_TPUS` here:"]},{"cell_type":"code","source":["TFLITE_FILENAME = '/content/drive/My Drive/STEM_1/dataset/export/efficientdet-lite-bikes.tflite'\n","NUMBER_OF_TPUS = 1"],"metadata":{"id":"GSnkSl8_JYjS"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LZdonJGCqieU"},"outputs":[],"source":["!edgetpu_compiler $TFLITE_FILENAME -d --num_segments=$NUMBER_OF_TPUS"]},{"cell_type":"markdown","metadata":{"id":"O2CjkduY02DF"},"source":["**Beware when using multiple segments:** The Edge TPU Comiler divides the model such that all segments have roughly equal amounts of parameter data, but that does not mean all segments have the same latency. Especially when dividing an SSD model such as EfficientDet, this results in a latency-imbalance between segments, because SSD models have a large post-processing op that actually executes on the CPU, not on the Edge TPU. So although segmenting your model this way is better than running the whole model on just one Edge TPU, we recommend that you segment the EfficientDet-Lite model using our [profiling-based partitioner tool](https://github.com/google-coral/libcoral/tree/master/coral/tools/partitioner#profiling-based-partitioner-for-the-edge-tpu-compiler), which measures each segment's latency on the Edge TPU and then iteratively adjusts the segmentation sizes to provide balanced latency between all segments."]},{"cell_type":"markdown","metadata":{"id":"KyBBvyqx0XRn"},"source":["## Download the files"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M43URVgg0ZcB"},"outputs":[],"source":["from google.colab import files\n","TFLITE_FILENAME = 'efficientdet-lite-bikes.tflite'\n","files.download(TFLITE_FILENAME)\n","files.download(TFLITE_FILENAME.replace('.tflite', '_edgetpu.tflite'))\n","files.download(LABELS_FILENAME)"]},{"cell_type":"markdown","metadata":{"id":"8fYwl4Rt8myF"},"source":["## Run the model on the Edge TPU"]},{"cell_type":"markdown","metadata":{"id":"Dv2Ingvx8pcI"},"source":["You can now run the model with acceleration on the Edge TPU.\n","\n","First, download an image of a salad on your device with an Edge TPU. For example, you can use the same one we tested above: \n","\n","```\n","wget https://storage.googleapis.com/cloud-ml-data/img/openimage/3/2520/3916261642_0a504acd60_o.jpg -O salad.jpg\n","```\n","\n","And then make sure you have [installed the PyCoral API](https://coral.ai/software/#pycoral-api).\n","\n","Now run an inference using [this example code for the PyCoral API](https://github.com/google-coral/pycoral/blob/master/examples/detect_image.py). Just clone the GitHub repo and run the example, passing it the model files from this tutorial:\n","\n","```\n","git clone https://github.com/google-coral/pycoral\n","\n","cd pycoral/examples/\n","\n","python3 detect_image.py \\\n","  --model efficientdet-lite-salads_edgetpu.tflite \\\n","  --labels salad-labels.txt \\\n","  --input salad.jpg \\\n","  --output salad_result.jpg\n","```\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"1DRNsZW-6-CQsR7p0i_49Z1dolM_8xyPN","timestamp":1667792635346},{"file_id":"https://github.com/google-coral/tutorials/blob/master/retrain_efficientdet_model_maker_tf2.ipynb","timestamp":1667756742492}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"gpuClass":"premium","accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}